{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn import linear_model\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import warnings\n",
    "def ignore_warn(*args, **kwargs):\n",
    "    pass\n",
    "warnings.warn = ignore_warn #ignore annoying warning (from sklearn and seaborn)\n",
    "\n",
    "data = pd.read_csv(\"model2.csv\")\n",
    "\n",
    "\n",
    "#merge\n",
    "x = data.iloc[:,0:7].values\n",
    "y = data.iloc[:,7:].values\n",
    "\n",
    "\n",
    "#train&split\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size = 0.33, random_state = 42)\n",
    "\n",
    "\n",
    "scores = list() # for accuracy scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 80 candidates, totalling 800 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 800 out of 800 | elapsed:  1.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Acc:  0.9450757575757576\n",
      "Best Estimators:  LogisticRegression(C=1438.44988828766, penalty='l1', random_state=42,\n",
      "                   solver='liblinear')\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Class 0       1.00      1.00      1.00        59\n",
      "     Class 1       0.95      0.93      0.94       151\n",
      "     Class 2       0.84      0.92      0.88        64\n",
      "     Class 3       0.85      0.94      0.89        53\n",
      "     Class 4       0.98      0.86      0.92        65\n",
      "     Class 5       0.99      0.99      0.99       136\n",
      "\n",
      "    accuracy                           0.95       528\n",
      "   macro avg       0.94      0.94      0.94       528\n",
      "weighted avg       0.95      0.95      0.95       528\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Logistic Regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "params = {'C': np.logspace(-4, 4, 20),\n",
    "         'penalty': ['l1', 'l2'],\n",
    "         'solver': ['lbfgs', 'liblinear']}\n",
    "gs_lr = GridSearchCV(LogisticRegression(random_state=42), params, verbose=1, cv=10)\n",
    "grid_search = gs_lr.fit(X_train, y_train)\n",
    "lr = LogisticRegression(C=grid_search.best_params_['C'],\n",
    "                                    penalty=grid_search.best_params_['penalty'],\n",
    "                                    solver=grid_search.best_params_['solver'])\n",
    "lr.fit(X_train, y_train)\n",
    "y_pred = lr.predict(X_test)\n",
    "acc_lr = accuracy_score(y_test, y_pred.round())\n",
    "print(\"Logistic Regression Acc: \", acc_lr)\n",
    "print(\"Best Estimators: \", grid_search.best_estimator_)\n",
    "scores.append(acc_lr)\n",
    "\n",
    "target_names = ['Class 0', 'Class 1', 'Class 2', 'Class 3', 'Class 4', 'Class 5']\n",
    "print(classification_report(y_true=y_test, y_pred=y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN acc:  0.9488636363636364\n",
      "Best Estimators:  KNeighborsClassifier(metric='manhattan', n_neighbors=19, weights='distance')\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Class 0       1.00      1.00      1.00        59\n",
      "     Class 1       0.94      1.00      0.97       151\n",
      "     Class 2       0.96      0.78      0.86        64\n",
      "     Class 3       0.90      0.98      0.94        53\n",
      "     Class 4       0.87      0.89      0.88        65\n",
      "     Class 5       1.00      0.96      0.98       136\n",
      "\n",
      "    accuracy                           0.95       528\n",
      "   macro avg       0.94      0.94      0.94       528\n",
      "weighted avg       0.95      0.95      0.95       528\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#k Nearest Neighbors\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "params = {'n_neighbors': np.arange(1,50),\n",
    "              'weights': ['uniform', 'distance'],\n",
    "              'metric': ['euclidean', 'manhattan', 'minkowski']} \n",
    "gs_knn = GridSearchCV(KNeighborsClassifier(),\n",
    "                            params,\n",
    "                            cv = 4,\n",
    "                            n_jobs = -1)\n",
    "grid_search = gs_knn.fit(X_train, y_train)\n",
    "\n",
    "knn = KNeighborsClassifier(metric=grid_search.best_params_['metric'],\n",
    "                                        n_neighbors=grid_search.best_params_['n_neighbors'],\n",
    "                                        weights=grid_search.best_params_['weights'])\n",
    "knn.fit(X_train, y_train)\n",
    "y_pred = knn.predict(X_test)\n",
    "acc_knn = accuracy_score(y_test, y_pred.round())\n",
    "print(\"KNN acc: \", acc_knn)\n",
    "print(\"Best Estimators: \", grid_search.best_estimator_)\n",
    "scores.append(acc_knn)\n",
    "\n",
    "target_names = ['Class 0', 'Class 1', 'Class 2', 'Class 3', 'Class 4', 'Class 5']\n",
    "print(classification_report(y_true=y_test, y_pred=y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC Acc:  0.990530303030303\n",
      "Best Estimators:  SVC(C=4, kernel='linear', random_state=0)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Class 0       1.00      1.00      1.00        59\n",
      "     Class 1       1.00      1.00      1.00       151\n",
      "     Class 2       0.97      0.98      0.98        64\n",
      "     Class 3       1.00      1.00      1.00        53\n",
      "     Class 4       0.97      0.97      0.97        65\n",
      "     Class 5       0.99      0.99      0.99       136\n",
      "\n",
      "    accuracy                           0.99       528\n",
      "   macro avg       0.99      0.99      0.99       528\n",
      "weighted avg       0.99      0.99      0.99       528\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#SVC\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "params = [{'C': [1, 2, 3, 4, 5], 'kernel': ['linear'], 'gamma': ['scale', 'auto']},\n",
    "        {'C': [1, 2, 3, 4, 5], 'kernel': ['rbf'], 'gamma': ['scale', 'auto']},\n",
    "        {'C': [1, 2, 3, 4, 5], 'kernel': ['sigmoid'], 'gamma': ['scale', 'auto']}]\n",
    "\n",
    "classifier = SVC(random_state = 0)\n",
    "gs = GridSearchCV(estimator = classifier,\n",
    "                    param_grid = params,\n",
    "                    cv = 10,\n",
    "                    n_jobs = -1)\n",
    "\n",
    "grid_search = gs.fit(X_train, y_train)\n",
    "\n",
    "svc = SVC(C=grid_search.best_params_[\"C\"],\n",
    "                kernel=grid_search.best_params_['kernel'],\n",
    "                gamma=grid_search.best_params_['gamma'])\n",
    "\n",
    "svc.fit(X_train, y_train)\n",
    "y_pred = svc.predict(X_test)\n",
    "acc_svc = accuracy_score(y_test, y_pred.round())\n",
    "print(\"SVC Acc: \", acc_svc)\n",
    "print(\"Best Estimators: \", grid_search.best_estimator_)\n",
    "scores.append(acc_svc)\n",
    "\n",
    "target_names = ['Class 0', 'Class 1', 'Class 2', 'Class 3', 'Class 4', 'Class 5']\n",
    "print(classification_report(y_true=y_test, y_pred=y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 588 candidates, totalling 1764 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree acc:  1.0\n",
      "Best Estimators:  DecisionTreeClassifier(max_leaf_nodes=9, random_state=42)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Class 0       1.00      1.00      1.00        59\n",
      "     Class 1       1.00      1.00      1.00       151\n",
      "     Class 2       1.00      1.00      1.00        64\n",
      "     Class 3       1.00      1.00      1.00        53\n",
      "     Class 4       1.00      1.00      1.00        65\n",
      "     Class 5       1.00      1.00      1.00       136\n",
      "\n",
      "    accuracy                           1.00       528\n",
      "   macro avg       1.00      1.00      1.00       528\n",
      "weighted avg       1.00      1.00      1.00       528\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 1764 out of 1764 | elapsed:    4.0s finished\n"
     ]
    }
   ],
   "source": [
    "#Decision Tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "params = {'criterion': ['gini', 'entropy'],\n",
    "            'max_leaf_nodes': list(range(2, 100)),\n",
    "            'min_samples_split': [2, 3, 4]}\n",
    "gs_dtc = GridSearchCV(DecisionTreeClassifier(random_state=42), params, verbose=1, cv=3)\n",
    "\n",
    "\n",
    "grid_search = gs_dtc.fit(X_train, y_train)\n",
    "\n",
    "dtc = DecisionTreeClassifier(criterion=grid_search.best_params_['criterion'],\n",
    "                                    max_leaf_nodes=grid_search.best_params_['max_leaf_nodes'],\n",
    "                                    min_samples_split=grid_search.best_params_['min_samples_split'])\n",
    "dtc.fit(X_train, y_train)\n",
    "y_pred = dtc.predict(X_test)\n",
    "acc_dt = accuracy_score(y_test, y_pred.round())\n",
    "print(\"Decision Tree acc: \", acc_dt)\n",
    "print(\"Best Estimators: \", grid_search.best_estimator_)\n",
    "scores.append(acc_dt)\n",
    "\n",
    "target_names = ['Class 0', 'Class 1', 'Class 2', 'Class 3', 'Class 4', 'Class 5']\n",
    "print(classification_report(y_true=y_test, y_pred=y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gaussian Naive Bayes Acc:  0.7064393939393939\n",
      "Best Estimators:  DecisionTreeClassifier(max_leaf_nodes=9, random_state=42)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Class 0       1.00      1.00      1.00        59\n",
      "     Class 1       1.00      0.50      0.67       151\n",
      "     Class 2       0.46      0.98      0.63        64\n",
      "     Class 3       0.82      1.00      0.90        53\n",
      "     Class 4       0.47      0.97      0.64        65\n",
      "     Class 5       1.00      0.43      0.61       136\n",
      "\n",
      "    accuracy                           0.71       528\n",
      "   macro avg       0.79      0.82      0.74       528\n",
      "weighted avg       0.85      0.71      0.70       528\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Gaussian Naive Bayes\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "nb = GaussianNB()\n",
    "nb.fit(X_train, y_train)\n",
    "y_pred = nb.predict(X_test)\n",
    "acc_nb = accuracy_score(y_test, y_pred.round())\n",
    "print(\"Gaussian Naive Bayes Acc: \", acc_nb)\n",
    "print(\"Best Estimators: \", grid_search.best_estimator_)\n",
    "scores.append(acc_nb)\n",
    "\n",
    "target_names = ['Class 0', 'Class 1', 'Class 2', 'Class 3', 'Class 4', 'Class 5']\n",
    "print(classification_report(y_true=y_test, y_pred=y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 125 candidates, totalling 1250 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Acc:  0.9981060606060606\n",
      "Best Estimators:  RandomForestClassifier(max_depth=6, min_samples_split=9, n_estimators=30,\n",
      "                       random_state=42)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Class 0       1.00      1.00      1.00        59\n",
      "     Class 1       1.00      1.00      1.00       151\n",
      "     Class 2       0.98      1.00      0.99        64\n",
      "     Class 3       1.00      1.00      1.00        53\n",
      "     Class 4       1.00      1.00      1.00        65\n",
      "     Class 5       1.00      0.99      1.00       136\n",
      "\n",
      "    accuracy                           1.00       528\n",
      "   macro avg       1.00      1.00      1.00       528\n",
      "weighted avg       1.00      1.00      1.00       528\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 1250 out of 1250 | elapsed:  1.8min finished\n"
     ]
    }
   ],
   "source": [
    "#Random Forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "params = {'n_estimators': [30, 40, 50, 60, 70],\n",
    "          'max_depth': [6, 8, 10, 12, 14],\n",
    "         'min_samples_split': [9, 11, 13, 15, 17]}\n",
    "gs_random_forest = GridSearchCV(RandomForestClassifier(random_state=42), params, verbose=1, cv=10)\n",
    "grid_search = gs_random_forest.fit(X_train, y_train)\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=grid_search.best_params_['n_estimators'],\n",
    "                                max_depth=grid_search.best_params_['max_depth'],\n",
    "                                min_samples_split=grid_search.best_params_['min_samples_split'],\n",
    "                                random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred = rf.predict(X_test)\n",
    "acc_rf = accuracy_score(y_test, y_pred.round())\n",
    "print(\"Random Forest Acc: \", acc_rf)\n",
    "print(\"Best Estimators: \", grid_search.best_estimator_)\n",
    "scores.append(acc_rf)\n",
    "\n",
    "target_names = ['Class 0', 'Class 1', 'Class 2', 'Class 3', 'Class 4', 'Class 5']\n",
    "print(classification_report(y_true=y_test, y_pred=y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.95\n"
     ]
    }
   ],
   "source": [
    "print('{:.2f}'.format(scores[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{('DecisionTreeModel', 1.0), ('SvcModel', 0.990530303030303), ('RandomForestModel', 0.9981060606060606), ('KnnModel', 0.9488636363636364), ('NaiveBayesModel', 0.7064393939393939), ('LogisticRegressionModel', 0.946969696969697)}\n"
     ]
    }
   ],
   "source": [
    "models = [\"LogisticRegressionModel\", \"KnnModel\",\n",
    "            \"SvcModel\", \"DecisionTreeModel\",\n",
    "            \"NaiveBayesModel\", \"RandomForestModel\"]\n",
    "result = zip(models, scores)\n",
    "result_set = set(result)\n",
    "print(result_set)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
